{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1999da74",
   "metadata": {
    "id": "vtqce6023nPX",
    "papermill": {
     "duration": 0.031303,
     "end_time": "2022-03-28T10:31:11.437895",
     "exception": false,
     "start_time": "2022-03-28T10:31:11.406592",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Drug Molecule Generation with VAE\n",
    "\n",
    "**Author:** [Victor Basu](https://www.linkedin.com/in/victor-basu-520958147)<br>\n",
    "**Date created:** 2022/03/10<br>\n",
    "**Last modified:** 2022/03/27<br>\n",
    "**Description:** Implementing a Convolutional Variational AutoEncoder (VAE) for Drug Discovery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cfb4822e-6132-4ce0-83af-659dd9547fe0",
   "metadata": {
    "id": "-A3c2JuEWdKJ",
    "papermill": {
     "duration": 5.158417,
     "end_time": "2022-03-28T10:31:27.425211",
     "exception": false,
     "start_time": "2022-03-28T10:31:22.266794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "#import ast\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd97f42c-485e-41da-aa16-a6755b9be0b2",
   "metadata": {
    "id": "-A3c2JuEWdKJ",
    "papermill": {
     "duration": 5.158417,
     "end_time": "2022-03-28T10:31:27.425211",
     "exception": false,
     "start_time": "2022-03-28T10:31:22.266794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from rdkit import Chem, RDLogger\n",
    "from rdkit.Chem import BondType\n",
    "from rdkit.Chem.Draw import MolsToGridImage\n",
    "from rdkit.Chem import Draw\n",
    "RDLogger.DisableLog(\"rdApp.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c9bd199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.13.0\n",
      "GPU available: []\n",
      "GPU in use: \n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"GPU available:\", tf.config.list_physical_devices('GPU'))\n",
    "print(\"GPU in use:\", tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af628890-5f86-4c1a-b4ed-1173cdff1d30",
   "metadata": {
    "id": "3jpjZBWoHyIV",
    "outputId": "725edd29-2b54-4859-c38f-713d6aba5747",
    "papermill": {
     "duration": 0.694725,
     "end_time": "2022-03-28T10:31:28.200012",
     "exception": false,
     "start_time": "2022-03-28T10:31:27.505287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMILES</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Score</th>\n",
       "      <th>Potency</th>\n",
       "      <th>Efficacy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CNCC1=NC2=C(C=C(C=C2)Cl)C(=N1)C3=CC=CN3</td>\n",
       "      <td>Inactive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CCSC(=NC1=CC=C(C=C1)C(F)(F)F)N.Cl</td>\n",
       "      <td>Inactive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CCN(CC1=CC(=CC=C1)S(=O)(=O)[O-])C2=CC=C(C=C2)C...</td>\n",
       "      <td>Inactive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CC1=CC=C(C=C1)S(=O)(=O)N2CCN(CC2)C3=NC(=NC4=CC...</td>\n",
       "      <td>Inactive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CC1=CC=C(C=C1)S(=O)(=O)N2CCN(CC2)C3=NC(=NC4=CC...</td>\n",
       "      <td>Inactive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              SMILES  Activity  Score  \\\n",
       "5            CNCC1=NC2=C(C=C(C=C2)Cl)C(=N1)C3=CC=CN3  Inactive    0.0   \n",
       "6                  CCSC(=NC1=CC=C(C=C1)C(F)(F)F)N.Cl  Inactive    0.0   \n",
       "7  CCN(CC1=CC(=CC=C1)S(=O)(=O)[O-])C2=CC=C(C=C2)C...  Inactive    0.0   \n",
       "8  CC1=CC=C(C=C1)S(=O)(=O)N2CCN(CC2)C3=NC(=NC4=CC...  Inactive    0.0   \n",
       "9  CC1=CC=C(C=C1)S(=O)(=O)N2CCN(CC2)C3=NC(=NC4=CC...  Inactive    0.0   \n",
       "\n",
       "   Potency  Efficacy  \n",
       "5      0.0       0.0  \n",
       "6      0.0       0.0  \n",
       "7      0.0       0.0  \n",
       "8      0.0       0.0  \n",
       "9      0.0       0.0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset1.csv')\n",
    "df.drop([0,1,2,3,4], inplace=True)\n",
    "df=df.rename(columns = {'PUBCHEM_EXT_DATASOURCE_SMILES':'SMILES','PUBCHEM_ACTIVITY_OUTCOME':'Activity', 'PUBCHEM_ACTIVITY_SCORE':'Score'})\n",
    "columns_to_drop = [col for col in df.columns if col not in ['SMILES', 'Activity', 'Score', 'Potency', 'Efficacy']]\n",
    "df = df.drop(columns = columns_to_drop)\n",
    "#df=df.drop(['Unnamed: 3','Unnamed: 4','Unnamed: 5'], axis=1)\n",
    "df = df.dropna(subset=['SMILES'])\n",
    "\n",
    "df=df.fillna(0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a2eb8a6d-2180-45ad-832d-68b36f7bd5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This part should now be 6000 inactive + 6000 active \n",
    "smiles = df['SMILES'].tolist()\n",
    "small_molecules = []\n",
    "for smile in smiles:\n",
    "    mol = Chem.MolFromSmiles(smile)\n",
    "    if mol.GetNumAtoms() <= 50:\n",
    "        small_molecules.append(smile)\n",
    "df_sampled = df[df['SMILES'].isin(small_molecules)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad8223b5-b972-4fda-af6a-8bcd9b4cc121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMILES</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Score</th>\n",
       "      <th>Potency</th>\n",
       "      <th>Efficacy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>271139</th>\n",
       "      <td>C1CCC(CC1)C2=CC=C(C=C2)S(=O)(=O)N3CCN(CC3)C4=C...</td>\n",
       "      <td>Inactive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301775</th>\n",
       "      <td>COC1=CC=C(C=C1)CNC(=O)CSC2=NC3=CC=CC=C3N=C2CC4...</td>\n",
       "      <td>Inactive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124783</th>\n",
       "      <td>C1OC2=C(O1)C=C(C=C2)NC(=O)CSC3=NC=NC4=CC=CC=C43</td>\n",
       "      <td>Inactive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56239</th>\n",
       "      <td>CC1CC2=C(N1C(=O)C)C=CC(=C2)S(=O)(=O)N3CCC(CC3)...</td>\n",
       "      <td>Inactive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75807</th>\n",
       "      <td>C=CCN1C(=NNC1=S)C(C2=CC=CC=C2)C3=CC=CC=C3</td>\n",
       "      <td>Inactive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227591</th>\n",
       "      <td>CC(C)(C)CC(=O)NCC(C1=CC2=C(C=C1)OCO2)N3CCN(CC3...</td>\n",
       "      <td>Inactive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74238</th>\n",
       "      <td>CC1=CC(=C(C=C1)C)NS(=O)(=O)C2=CC=C(C=C2)OCC(=O...</td>\n",
       "      <td>Inactive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175953</th>\n",
       "      <td>CCC(=O)C1=CC=C(C=C1)OCC(=O)NC2CCCC2</td>\n",
       "      <td>Inactive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252727</th>\n",
       "      <td>CCOC1=C(C=CC(=C1)/C=C/2\\C(=O)N(C(=NC3=CC=CC=C3...</td>\n",
       "      <td>Inactive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123625</th>\n",
       "      <td>CC1CN(CC(O1)C)C(=O)C(C)SC2=NC3=CC=CC=C3S2</td>\n",
       "      <td>Inactive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5119 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   SMILES  Activity  Score  \\\n",
       "271139  C1CCC(CC1)C2=CC=C(C=C2)S(=O)(=O)N3CCN(CC3)C4=C...  Inactive    0.0   \n",
       "301775  COC1=CC=C(C=C1)CNC(=O)CSC2=NC3=CC=CC=C3N=C2CC4...  Inactive    0.0   \n",
       "124783    C1OC2=C(O1)C=C(C=C2)NC(=O)CSC3=NC=NC4=CC=CC=C43  Inactive    0.0   \n",
       "56239   CC1CC2=C(N1C(=O)C)C=CC(=C2)S(=O)(=O)N3CCC(CC3)...  Inactive    0.0   \n",
       "75807           C=CCN1C(=NNC1=S)C(C2=CC=CC=C2)C3=CC=CC=C3  Inactive    0.0   \n",
       "...                                                   ...       ...    ...   \n",
       "227591  CC(C)(C)CC(=O)NCC(C1=CC2=C(C=C1)OCO2)N3CCN(CC3...  Inactive    0.0   \n",
       "74238   CC1=CC(=C(C=C1)C)NS(=O)(=O)C2=CC=C(C=C2)OCC(=O...  Inactive    0.0   \n",
       "175953                CCC(=O)C1=CC=C(C=C1)OCC(=O)NC2CCCC2  Inactive    0.0   \n",
       "252727  CCOC1=C(C=CC(=C1)/C=C/2\\C(=O)N(C(=NC3=CC=CC=C3...  Inactive    0.0   \n",
       "123625          CC1CN(CC(O1)C)C(=O)C(C)SC2=NC3=CC=CC=C3S2  Inactive    0.0   \n",
       "\n",
       "        Potency  Efficacy  \n",
       "271139      0.0       0.0  \n",
       "301775      0.0       0.0  \n",
       "124783      0.0       0.0  \n",
       "56239       0.0       0.0  \n",
       "75807       0.0       0.0  \n",
       "...         ...       ...  \n",
       "227591      0.0       0.0  \n",
       "74238       0.0       0.0  \n",
       "175953      0.0       0.0  \n",
       "252727      0.0       0.0  \n",
       "123625      0.0       0.0  \n",
       "\n",
       "[5119 rows x 5 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df = df_sampled.sample(frac=0.015, random_state=42)\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "205440a3-0dec-4430-a87b-34b2fb73332f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdmolops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2ae30769-74d0-4608-8dba-01a82c69eb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles = filtered_df['SMILES'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b35d67",
   "metadata": {
    "id": "nqMBVEtntlhi",
    "papermill": {
     "duration": 0.02771,
     "end_time": "2022-03-28T10:31:28.642565",
     "exception": false,
     "start_time": "2022-03-28T10:31:28.614855",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Molecular Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0b3b42db-7df1-46da-ba67-ab3a08805f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['P', 'O', 'Na', 'Cl', 'Br', 'S', 'K', 'F', 'N', 'I', 'C', 'B']\n"
     ]
    }
   ],
   "source": [
    "search_elements=[]\n",
    "for smile in smiles:\n",
    "    mol = Chem.MolFromSmiles(smile)\n",
    "    atoms = list(set([atom.GetSymbol() for atom in mol.GetAtoms()]))\n",
    "    search_elements += atoms\n",
    "    search_elements = list(set(search_elements))\n",
    "\n",
    "print(search_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ddce30f1-6c88-415f-a7aa-47494b6c6c86",
   "metadata": {
    "id": "2a28g7DsyWfP",
    "outputId": "af1f59ea-7f7e-4e0b-dcc3-4de1cf58f490",
    "papermill": {
     "duration": 0.224506,
     "end_time": "2022-03-28T10:31:28.586286",
     "exception": false,
     "start_time": "2022-03-28T10:31:28.361780",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bond_mapping = {\"SINGLE\": 0, \"DOUBLE\": 1, \"TRIPLE\": 2, \"AROMATIC\": 3}\n",
    "bond_mapping.update(\n",
    "    {0: BondType.SINGLE, 1: BondType.DOUBLE, 2: BondType.TRIPLE, 3: BondType.AROMATIC}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ec0deeac-7a0d-43e2-af95-9b7e4bb1696d",
   "metadata": {
    "id": "2a28g7DsyWfP",
    "outputId": "af1f59ea-7f7e-4e0b-dcc3-4de1cf58f490",
    "papermill": {
     "duration": 0.224506,
     "end_time": "2022-03-28T10:31:28.586286",
     "exception": false,
     "start_time": "2022-03-28T10:31:28.361780",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'P': 0, 'O': 1, 'Na': 2, 'Cl': 3, 'Br': 4, 'S': 5, 'K': 6, 'F': 7, 'N': 8, 'I': 9, 'C': 10, 'B': 11, 0: 'P', 1: 'O', 2: 'Na', 3: 'Cl', 4: 'Br', 5: 'S', 6: 'K', 7: 'F', 8: 'N', 9: 'I', 10: 'C', 11: 'B'}\n",
      "Max molecule size: 119\n",
      "Character set Length: 12\n"
     ]
    }
   ],
   "source": [
    "MAX_MOLSIZE = max(filtered_df['SMILES'].str.len())\n",
    "SMILE_to_index = dict((c, i) for i, c in enumerate(SMILE_CHARSET))\n",
    "index_to_SMILE = dict((i, c) for i, c in enumerate(SMILE_CHARSET))\n",
    "atom_mapping = dict(SMILE_to_index)\n",
    "atom_mapping.update(index_to_SMILE)\n",
    "print(atom_mapping)\n",
    "print(\"Max molecule size: {}\".format(MAX_MOLSIZE))\n",
    "print(\"Character set Length: {}\".format(len(SMILE_CHARSET)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8c11019d",
   "metadata": {
    "id": "0L44eVm-tkSL",
    "papermill": {
     "duration": 0.035246,
     "end_time": "2022-03-28T10:31:28.705523",
     "exception": false,
     "start_time": "2022-03-28T10:31:28.670277",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_ATOMS = 50 #Max number of atoms\n",
    "ATOM_DIM = len(SMILE_CHARSET)  # Number of atom types\n",
    "BOND_DIM = 5 # Number of bond types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "633e2d91-9565-4933-b17e-cb9251ed8569",
   "metadata": {
    "id": "JrFJum15nX8j",
    "papermill": {
     "duration": 0.045361,
     "end_time": "2022-03-28T10:31:28.778864",
     "exception": false,
     "start_time": "2022-03-28T10:31:28.733503",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    " def smiles_to_graph(smiles):\n",
    "    # Converts SMILES to molecule object\n",
    "    molecule = Chem.MolFromSmiles(smiles)\n",
    "\n",
    "    # Initialize adjacency and feature tensor\n",
    "    adjacency = np.zeros((BOND_DIM, NUM_ATOMS, NUM_ATOMS), \"float32\")\n",
    "    features = np.zeros((NUM_ATOMS, ATOM_DIM), \"float32\")\n",
    "\n",
    "    # Bond weights\n",
    "    bond_weights = {\n",
    "        \"SINGLE\": 1.0,\n",
    "        \"DOUBLE\": 2.0,\n",
    "        \"TRIPLE\": 3.0,\n",
    "        \"AROMATIC\": 2.5}\n",
    "\n",
    "    # Loop over each atom in molecule\n",
    "    for atom in molecule.GetAtoms():\n",
    "        i = atom.GetIdx()\n",
    "        atom_type = atom_mapping[atom.GetSymbol()]\n",
    "        features[i] = np.eye(ATOM_DIM)[atom_type]\n",
    "\n",
    "        # Loop over one-hop neighbors\n",
    "        for neighbor in atom.GetNeighbors():\n",
    "            j = neighbor.GetIdx()\n",
    "            bond = molecule.GetBondBetweenAtoms(i, j)\n",
    "            bond_type = bond.GetBondType().name\n",
    "            bond_weight = bond_weights.get(bond_type, 1.0)  \n",
    "\n",
    "            bond_type_idx = bond_mapping[bond_type]\n",
    "            adjacency[bond_type_idx, [i, j], [j, i]] = bond_weight\n",
    "\n",
    "    # Where no bond, add 1 to last channel (indicating \"non-bond\")\n",
    "    # Notice: channels-first\n",
    "    adjacency[-1, np.sum(adjacency, axis=0) == 0] = 1\n",
    "\n",
    "    # Where no atom, add 1 to last column (indicating \"non-atom\")\n",
    "    features[np.where(np.sum(features, axis=1) == 0)[0], -1] = 1\n",
    "\n",
    "    return adjacency, features\n",
    "\n",
    "\n",
    "def graph_to_molecule(adjacency, features):\n",
    "\n",
    "    # RWMol is a molecule object intended to be edited\n",
    "    molecule = Chem.RWMol()\n",
    "\n",
    "    # Remove \"no atoms\" & atoms with no bonds\n",
    "    keep_idx = np.where(\n",
    "        (np.argmax(features, axis=1) != ATOM_DIM - 1)\n",
    "        & (np.sum(adjacency[:-1], axis=(0, 1)) != 0))[0]\n",
    "\n",
    "    features = features[keep_idx]\n",
    "    adjacency = adjacency[:, keep_idx, :][:, :, keep_idx]\n",
    "\n",
    "    # Add atoms to molecule\n",
    "    for atom_type_idx in np.argmax(features, axis=1):\n",
    "        atom = Chem.Atom(atom_mapping[atom_type_idx])\n",
    "        _ = molecule.AddAtom(atom)\n",
    "\n",
    "    added_bonds = set()\n",
    "    (bonds_ij, atoms_i, atoms_j) = np.where(np.triu(adjacency) == 1)\n",
    "    for (bond_ij, atom_i, atom_j) in zip(bonds_ij, atoms_i, atoms_j):\n",
    "        if atom_i == atom_j or bond_ij == BOND_DIM - 1:\n",
    "            continue\n",
    "        bond_type = bond_mapping[bond_ij]\n",
    "        if (atom_i, atom_j) in added_bonds or (atom_j, atom_i) in added_bonds:\n",
    "            \n",
    "            continue\n",
    "        molecule.AddBond(int(atom_i), int(atom_j), bond_type)\n",
    "        added_bonds.add((atom_i, atom_j))\n",
    "\n",
    "    # Sanitize the molecule; for more information on sanitization, see\n",
    "    # https://www.rdkit.org/docs/RDKit_Book.html#molecular-sanitization\n",
    "    flag = Chem.SanitizeMol(molecule, catchErrors=True)\n",
    "    if flag != Chem.SanitizeFlags.SANITIZE_NONE:\n",
    "        return None\n",
    "\n",
    "    return molecule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d336fd7e",
   "metadata": {
    "papermill": {
     "duration": 0.028121,
     "end_time": "2022-03-28T10:31:28.962798",
     "exception": false,
     "start_time": "2022-03-28T10:31:28.934677",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##  Generate training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fd4437fa",
   "metadata": {
    "id": "QkK00Zo_VXvs",
    "papermill": {
     "duration": 0.042545,
     "end_time": "2022-03-28T10:31:29.184181",
     "exception": false,
     "start_time": "2022-03-28T10:31:29.141636",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    Directly from Reference: https://keras.io/examples/generative/wgan-graphs/\n",
    "'''\n",
    "class RelationalGraphConvLayer(keras.layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        units=128,\n",
    "        activation=\"relu\",\n",
    "        use_bias=False,\n",
    "        kernel_initializer=\"glorot_uniform\",\n",
    "        bias_initializer=\"zeros\",\n",
    "        kernel_regularizer=None,\n",
    "        bias_regularizer=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.units = units\n",
    "        self.activation = keras.activations.get(activation)\n",
    "        self.use_bias = use_bias\n",
    "        self.kernel_initializer = keras.initializers.get(kernel_initializer)\n",
    "        self.bias_initializer = keras.initializers.get(bias_initializer)\n",
    "        self.kernel_regularizer = keras.regularizers.get(kernel_regularizer)\n",
    "        self.bias_regularizer = keras.regularizers.get(bias_regularizer)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        bond_dim = input_shape[0][1]\n",
    "        atom_dim = input_shape[1][2]\n",
    "\n",
    "        self.kernel = self.add_weight(\n",
    "            shape=(bond_dim, atom_dim, self.units),\n",
    "            initializer=self.kernel_initializer,\n",
    "            regularizer=self.kernel_regularizer,\n",
    "            trainable=True,\n",
    "            name=\"W\",\n",
    "            dtype=tf.float32,\n",
    "        )\n",
    "\n",
    "        if self.use_bias:\n",
    "            self.bias = self.add_weight(\n",
    "                shape=(bond_dim, 1, self.units),\n",
    "                initializer=self.bias_initializer,\n",
    "                regularizer=self.bias_regularizer,\n",
    "                trainable=True,\n",
    "                name=\"b\",\n",
    "                dtype=tf.float32,\n",
    "            )\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        adjacency, features = inputs\n",
    "        # Aggregate information from neighbors\n",
    "        x = tf.matmul(adjacency, features[:, None, :, :])\n",
    "        # Apply linear transformation\n",
    "        x = tf.matmul(x, self.kernel)\n",
    "        if self.use_bias:\n",
    "            x += self.bias\n",
    "        # Reduce bond types dim\n",
    "        x_reduced = tf.reduce_sum(x, axis=1)\n",
    "        # Apply non-linear transformation\n",
    "        return self.activation(x_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d787107",
   "metadata": {
    "id": "N-BPcIQszd3i",
    "papermill": {
     "duration": 0.027975,
     "end_time": "2022-03-28T10:31:29.239986",
     "exception": false,
     "start_time": "2022-03-28T10:31:29.212011",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Build the Encoder and Decoder\n",
    "The Encoder takes as input a molecule's graph adjacency matrix and feature matrix.\n",
    "These features are processed via a Graph Convolution layer, then are flattened and\n",
    "processed by several Dense layers to derive `z_mean` and `log_var`, the\n",
    "latent-space representation of the molecule.\n",
    "**Graph Convolution layer**: The relational graph convolution layer implements\n",
    "non-linearly transformed neighbourhood aggregations. We can define these layers as\n",
    "follows:\n",
    "`H_hat**(l+1) = σ(D_hat**(-1) * A_hat * H_hat**(l+1) * W**(l))`\n",
    "Where `σ` denotes the non-linear transformation (commonly a ReLU activation), `A` the\n",
    "adjacency tensor, `H_hat**(l)` the feature tensor at the `l-th` layer, `D_hat**(-1)` the\n",
    "inverse diagonal degree tensor of `A_hat`, and `W_hat**(l)` the trainable weight tensor\n",
    "at the `l-th` layer. Specifically, for each bond type (relation), the degree tensor\n",
    "expresses, in the diagonal, the number of bonds attached to each atom.\n",
    "Source:\n",
    "[WGAN-GP with R-GCN for the generation of small molecular graphs](https://keras.io/examples/generative/wgan-graphs/))\n",
    "The Decoder takes as input the latent-space representation and predicts\n",
    "the graph adjacency matrix and feature matrix of the corresponding molecules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dab1702a-7054-4b50-8d5c-2a2e2fbb2722",
   "metadata": {
    "id": "OH2zSBpMgrFF",
    "papermill": {
     "duration": 0.041761,
     "end_time": "2022-03-28T10:31:29.309687",
     "exception": false,
     "start_time": "2022-03-28T10:31:29.267926",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SymLayer(layers.Layer):\n",
    "    def call(self,x):\n",
    "        return (x + tf.transpose(x, (0,1,3,2,))) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3a065070-1435-4ac9-82e4-818472cc0119",
   "metadata": {
    "id": "OH2zSBpMgrFF",
    "papermill": {
     "duration": 0.041761,
     "end_time": "2022-03-28T10:31:29.309687",
     "exception": false,
     "start_time": "2022-03-28T10:31:29.267926",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_encoder(gconv_units, latent_dim, adjacency_shape, feature_shape, dense_units, dropout_rate, regularizer=None):\n",
    "    adjacency = keras.layers.Input(shape=adjacency_shape, name=\"adjacency_input\")\n",
    "    features = keras.layers.Input(shape=feature_shape, name=\"feature_input\")\n",
    "    scores = keras.layers.Input(shape=(1,), name=\"score_input\")  # Conditional input (scalar)\n",
    "\n",
    "    # Graph convolution layers\n",
    "    features_transformed = features\n",
    "    for units in gconv_units:\n",
    "        features_transformed = RelationalGraphConvLayer(units)(\n",
    "            [adjacency, features_transformed]\n",
    "        )\n",
    "\n",
    "    # Reduce 2D representation to 1D\n",
    "    x = keras.layers.GlobalAveragePooling1D()(features_transformed)\n",
    "\n",
    "    # Concatenate the score (condition) to the reduced graph representation\n",
    "    x = keras.layers.Concatenate()([x, scores])\n",
    "\n",
    "    # Fully connected layers\n",
    "    for units in dense_units:\n",
    "        x = layers.Dense(units, activation=\"relu\", kernel_regularizer=regularizer)(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "\n",
    "    # Latent space\n",
    "    z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "    z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "\n",
    "    # Create encoder model\n",
    "    encoder = keras.Model(inputs=[adjacency, features, scores], outputs=[z_mean, z_log_var], name=\"encoder\")\n",
    "\n",
    "    return encoder\n",
    "\n",
    "\n",
    "def get_decoder(dense_units, latent_dim, adjacency_shape, feature_shape, dropout_rate, regularizer=None):\n",
    "    latent_input = keras.Input(shape=(latent_dim,), name=\"latent_input\")\n",
    "    scores = keras.Input(shape=(1,), name=\"score_input\")  # Conditional input (scalar)\n",
    "\n",
    "    # Concatenate latent input with the conditional score\n",
    "    x = keras.layers.Concatenate()([latent_input, scores])\n",
    "\n",
    "    # Dense layers\n",
    "    for units in dense_units:\n",
    "        x = keras.layers.Dense(units, activation=\"tanh\", kernel_regularizer=regularizer)(x)\n",
    "        x = keras.layers.Dropout(dropout_rate)(x)\n",
    "\n",
    "    # Adjacency reconstruction\n",
    "    adj_output = keras.layers.Dense(tf.math.reduce_prod(adjacency_shape).numpy().astype(int))(x)\n",
    "    adj_output = keras.layers.Reshape(adjacency_shape)(adj_output)\n",
    "    print(type(adj_output))\n",
    "    adj_output = SymLayer()(adj_output)\n",
    "    #adj_output = Lambda(lambda x: (x + tf.transpose(x, (0, 1, 3, 2))) / 2)(adj_output)\n",
    "    print(type(adj_output))\n",
    "\n",
    "    # Feature reconstruction\n",
    "    feat_output = keras.layers.Dense(tf.math.reduce_prod(feature_shape).numpy().astype(int))(x)\n",
    "    feat_output = keras.layers.Reshape(feature_shape)(feat_output)\n",
    "    feat_output = keras.layers.Softmax(axis=2)(feat_output)\n",
    "\n",
    "    # Create decoder model\n",
    "    decoder = keras.Model(inputs=[latent_input, scores], outputs=[adj_output, feat_output], name=\"decoder\")\n",
    "\n",
    "    return decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf196d9d",
   "metadata": {
    "id": "DRklbvcOzunX",
    "papermill": {
     "duration": 0.027638,
     "end_time": "2022-03-28T10:31:29.485618",
     "exception": false,
     "start_time": "2022-03-28T10:31:29.457980",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Build the VAE\n",
    "This model is trained to optimize four losses:\n",
    "* Categorical crossentropy\n",
    "* KL divergence loss\n",
    "* Property prediction loss\n",
    "* Graph loss (gradient penalty)\n",
    "The categorical crossentropy loss function measures the model's\n",
    "reconstruction accuracy. The Property prediction loss estimates the mean squared\n",
    "error between predicted and actual properties after running the latent representation\n",
    "through a property prediction model. The property\n",
    "prediction of the model is optimized via binary crossentropy. The gradient\n",
    "penalty is further guided by the model's property (SAS) prediction.\n",
    "A gradient penalty is an alternative soft constraint on the\n",
    "1-Lipschitz continuity as an improvement upon the gradient clipping scheme from the\n",
    "original neural network\n",
    "(\"1-Lipschitz continuity\" means that the norm of the gradient is at most 1 at evey single\n",
    "point of the function).\n",
    "It adds a regularization term to the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d6481ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, beta=1.0, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def call(self, inputs):\n",
    "        adjacency, features, scores = inputs\n",
    "        z_mean, z_log_var = self.encoder([adjacency, features, scores])\n",
    "        z = self.reparameterize(z_mean, z_log_var)\n",
    "        return self.decoder([z, scores])\n",
    "        \n",
    "    def sampling(self, args):\n",
    "        \"\"\"\n",
    "        Reparameterization trick: Sample from a Gaussian distribution using\n",
    "        z = z_mean + epsilon * exp(z_log_var / 2), where epsilon is sampled from N(0, 1).\n",
    "        \"\"\"\n",
    "        z_mean, z_log_var = args\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))  # Standard normal noise\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "873bb43b-2408-4424-9ea2-056675210b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3276, 5, 50, 50)\n",
      "(3276, 50, 12)\n",
      "(3276, 1)\n",
      "(819, 5, 50, 50)\n",
      "(819, 50, 12)\n",
      "(819, 1)\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(filtered_df,test_size=0.2,random_state=42)\n",
    "\n",
    "train_df, val_df = train_test_split(train, test_size=0.2, random_state=42)\n",
    "\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "val_df.reset_index(drop=True, inplace=True)\n",
    "test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "adj_train, fea_train, score_train = [], [], []\n",
    "adj_val, fea_val, score_val = [], [], []\n",
    "\n",
    "for idx in range(len(train_df)):\n",
    "    adjacency, features = smiles_to_graph(train_df.loc[idx][\"SMILES\"])\n",
    "    score = train_df.loc[idx][\"Score\"]\n",
    "    adj_train.append(adjacency)\n",
    "    fea_train.append(features)\n",
    "    score_train.append(score)\n",
    "\n",
    "for idx in range(len(val_df)):\n",
    "    adjacency, features = smiles_to_graph(val_df.loc[idx][\"SMILES\"])\n",
    "    score = val_df.loc[idx][\"Score\"]\n",
    "    adj_val.append(adjacency)\n",
    "    fea_val.append(features)\n",
    "    score_val.append(score)\n",
    "\n",
    "    \n",
    "adj_train = np.array(adj_train)/3\n",
    "fea_train = np.array(fea_train)\n",
    "score_train = np.array(score_train).reshape(-1,1)\n",
    "\n",
    "adj_val = np.array(adj_val)/3\n",
    "fea_val = np.array(fea_val)\n",
    "score_val = np.array(score_val).reshape(-1,1)\n",
    "\n",
    "print(adj_train.shape)\n",
    "print(fea_train.shape)\n",
    "print(score_train.shape)\n",
    "print(adj_val.shape)\n",
    "print(fea_val.shape)\n",
    "print(score_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8a5974e6-4fc9-4487-8a1b-ed8581d964cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.         0.33333334 0.         ... 0.         0.         0.        ]\n",
      "  [0.33333334 0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.8333333  ... 0.         0.         0.        ]\n",
      "  [0.         0.8333333  0.         ... 0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "\n",
      " [[0.33333334 0.         0.33333334 ... 0.33333334 0.33333334 0.33333334]\n",
      "  [0.         0.33333334 0.         ... 0.33333334 0.33333334 0.33333334]\n",
      "  [0.33333334 0.         0.33333334 ... 0.33333334 0.33333334 0.33333334]\n",
      "  ...\n",
      "  [0.33333334 0.33333334 0.33333334 ... 0.33333334 0.33333334 0.33333334]\n",
      "  [0.33333334 0.33333334 0.33333334 ... 0.33333334 0.33333334 0.33333334]\n",
      "  [0.33333334 0.33333334 0.33333334 ... 0.33333334 0.33333334 0.33333334]]]\n"
     ]
    }
   ],
   "source": [
    "print(adj_train[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc80469e",
   "metadata": {
    "id": "TWT2Bceh5yn3",
    "papermill": {
     "duration": 0.027567,
     "end_time": "2022-03-28T10:31:29.625813",
     "exception": false,
     "start_time": "2022-03-28T10:31:29.598246",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1993e7c7-b449-4d9f-a1de-04c0d5ad6720",
   "metadata": {
    "id": "K8UyJdg8HfxT",
    "outputId": "86225971-a04b-4a02-a3c3-eaab04cf191a",
    "papermill": {
     "duration": 380.350703,
     "end_time": "2022-03-28T10:37:50.068282",
     "exception": false,
     "start_time": "2022-03-28T10:31:29.717579",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "batch_size = 24\n",
    "EPOCHS = 10\n",
    "VAE_LR = 2e-4\n",
    "LATENT_DIM = 16  # Size of the latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "81a1d1ff-e341-44b1-ba50-1f72575399bc",
   "metadata": {
    "id": "K8UyJdg8HfxT",
    "outputId": "86225971-a04b-4a02-a3c3-eaab04cf191a",
    "papermill": {
     "duration": 380.350703,
     "end_time": "2022-03-28T10:37:50.068282",
     "exception": false,
     "start_time": "2022-03-28T10:31:29.717579",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'keras.src.engine.keras_tensor.KerasTensor'>\n",
      "<class 'keras.src.engine.keras_tensor.KerasTensor'>\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.regularizers import l1_l2\n",
    "encoder = get_encoder(\n",
    "    gconv_units=[9],\n",
    "    adjacency_shape=(BOND_DIM, NUM_ATOMS, NUM_ATOMS),\n",
    "    feature_shape=(NUM_ATOMS, ATOM_DIM),\n",
    "    latent_dim=LATENT_DIM,\n",
    "    dense_units=[256, 512],\n",
    "    dropout_rate=0,\n",
    "    regularizer=l1_l2(l1=1e-3, l2=1e-3)\n",
    ")\n",
    "decoder = get_decoder(\n",
    "    dense_units=[256, 512, 1024],\n",
    "    dropout_rate=0.2,\n",
    "    latent_dim=LATENT_DIM,\n",
    "    adjacency_shape=(BOND_DIM, NUM_ATOMS, NUM_ATOMS),\n",
    "    feature_shape=(NUM_ATOMS, ATOM_DIM), \n",
    "    regularizer=l1_l2(l1=0.1, l2=0.1)\n",
    ")\n",
    "vae = VAE(encoder, decoder)\n",
    "\n",
    "vae.compile(optimizer=keras.optimizers.Adam(learning_rate=VAE_LR))\n",
    "\n",
    "#Normalize score matrix\n",
    "min_score = np.min(score_train)\n",
    "max_score = np.max(score_train) \n",
    "score_train_normalized = (score_train - min_score) / (max_score - min_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "55e8d57a-b6c3-401e-af6e-1d8df8f3f0a7",
   "metadata": {
    "id": "K8UyJdg8HfxT",
    "outputId": "86225971-a04b-4a02-a3c3-eaab04cf191a",
    "papermill": {
     "duration": 380.350703,
     "end_time": "2022-03-28T10:37:50.068282",
     "exception": false,
     "start_time": "2022-03-28T10:31:29.717579",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((adj_train, fea_train, score_train)).batch(batch_size)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((adj_val, fea_val, score_val)).batch(batch_size)\n",
    "\n",
    "val_loss_list = []\n",
    "train_loss_list = []\n",
    "\n",
    "#These starting values are arbitary. We picked those starting values because our loss is constantly lower than 100.\n",
    "#We picked reconstruction_loss < prev to lower the beta first, because we suspected there is a reconstruction issue\n",
    "prev_rec_loss = 100\n",
    "reconstruction_loss = 101\n",
    "beta = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d0744eef-5417-485b-8279-5ae321058d60",
   "metadata": {
    "id": "K8UyJdg8HfxT",
    "outputId": "86225971-a04b-4a02-a3c3-eaab04cf191a",
    "papermill": {
     "duration": 380.350703,
     "end_time": "2022-03-28T10:37:50.068282",
     "exception": false,
     "start_time": "2022-03-28T10:31:29.717579",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Train Loss: 61.168907165527344, KL Loss: 7.120011806488037, Reconstruction Loss: 50.62772750854492\n",
      "Validation Loss: 50.37357711791992, KL Loss: 7.551031112670898, Reconstruction Loss: 49.380767822265625\n",
      "BETA is:  0.05500000000000001\n",
      "Epoch 2/10\n",
      "Train Loss: 50.16172409057617, KL Loss: 6.893106937408447, Reconstruction Loss: 49.703346252441406\n",
      "Validation Loss: 49.048683166503906, KL Loss: 7.292844295501709, Reconstruction Loss: 47.89186477661133\n",
      "BETA is:  0.04950000000000001\n",
      "Epoch 3/10\n",
      "Train Loss: 48.23603057861328, KL Loss: 8.59839153289795, Reconstruction Loss: 48.40557098388672\n",
      "Validation Loss: 47.653785705566406, KL Loss: 9.818497657775879, Reconstruction Loss: 46.010799407958984\n",
      "BETA is:  0.044550000000000006\n",
      "Epoch 4/10\n",
      "Train Loss: 47.532657623291016, KL Loss: 9.545109748840332, Reconstruction Loss: 48.02184295654297\n",
      "Validation Loss: 47.084415435791016, KL Loss: 11.15727424621582, Reconstruction Loss: 45.52397537231445\n",
      "BETA is:  0.040095000000000006\n",
      "Epoch 5/10\n",
      "Train Loss: 47.188385009765625, KL Loss: 9.410938262939453, Reconstruction Loss: 47.81836700439453\n",
      "Validation Loss: 46.95398712158203, KL Loss: 10.880115509033203, Reconstruction Loss: 45.59580993652344\n",
      "BETA is:  0.04410450000000001\n",
      "Epoch 6/10\n",
      "Train Loss: 47.03357696533203, KL Loss: 8.514874458312988, Reconstruction Loss: 47.84089660644531\n",
      "Validation Loss: 46.84892272949219, KL Loss: 9.998165130615234, Reconstruction Loss: 45.246524810791016\n",
      "BETA is:  0.048514950000000015\n",
      "Epoch 7/10\n",
      "Train Loss: 46.9801025390625, KL Loss: 8.12488842010498, Reconstruction Loss: 47.2774658203125\n",
      "Validation Loss: 46.75304412841797, KL Loss: 9.54789924621582, Reconstruction Loss: 45.22182083129883\n",
      "BETA is:  0.05336644500000002\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_33344\\2337181059.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m             )\n\u001b[0;32m     30\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreconstruction_loss\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mbeta\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mkl_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;31m# Backpropagation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvae\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[0mvae\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvae\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtotal_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1059\u001b[0m               output_gradients))\n\u001b[0;32m   1060\u001b[0m       output_gradients = [None if x is None else ops.convert_to_tensor(x)\n\u001b[0;32m   1061\u001b[0m                           for x in output_gradients]\n\u001b[0;32m   1062\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1063\u001b[1;33m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[0;32m   1064\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1065\u001b[0m         \u001b[0mflat_targets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1066\u001b[0m         \u001b[0mflat_sources\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     63\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m     raise ValueError(\n\u001b[0;32m     65\u001b[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[0;32m     68\u001b[0m       \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m       \u001b[0msources\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[0mgradient_name_scope\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"gradient_tape/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m   1361\u001b[0m   \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1362\u001b[0m   if (isinstance(grad, ops.Tensor) and\n\u001b[0;32m   1363\u001b[0m       \u001b[0m_ShapesFullySpecifiedAndEqual\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m       grad.dtype in (dtypes.int32, dtypes.float32)):\n\u001b[1;32m-> 1365\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1366\u001b[0m   \u001b[1;32massert\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_dtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\" vs. \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1368\u001b[0m   (sx, rx, must_reduce_x), (sy, ry, must_reduce_y) = (\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   7327\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7329\u001b[0m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7330\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7331\u001b[1;33m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7332\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7333\u001b[0m       return mul_eager_fallback(\n\u001b[0;32m   7334\u001b[0m           x, y, name=name, ctx=_ctx)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Epoch {epoch + 1}/{EPOCHS}\")\n",
    "    \n",
    "    if reconstruction_loss < prev_rec_loss * 0.99:\n",
    "        beta = max(beta * 0.9, 0.001)  \n",
    "    else:  \n",
    "        beta = min(beta * 1.1, 0.1)\n",
    "    prev_rec_loss = reconstruction_loss\n",
    "    \n",
    "    # Training Loop\n",
    "    train_loss = 0\n",
    "    for step, (adjacency, features, scores) in enumerate(train_dataset):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass\n",
    "            z_mean, z_log_var = vae.encoder([adjacency, features, scores])\n",
    "            z = vae.sampling([z_mean, z_log_var])\n",
    "            adj_reconstruction, feature_reconstruction = vae.decoder([z, scores])\n",
    "\n",
    "            # Compute losses\n",
    "            adj_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(keras.losses.binary_crossentropy(adjacency, adj_reconstruction), axis=(1, 2))\n",
    "            )\n",
    "            feat_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(keras.losses.categorical_crossentropy(features, feature_reconstruction), axis=1)\n",
    "            )\n",
    "            reconstruction_loss = 0.6*adj_loss + 0.4*feat_loss\n",
    "            kl_loss = -0.5 * tf.reduce_mean(\n",
    "                tf.reduce_sum(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=1)\n",
    "            )\n",
    "            total_loss = reconstruction_loss + beta * kl_loss\n",
    "\n",
    "        # Backpropagation\n",
    "        grads = tape.gradient(total_loss, vae.trainable_weights)\n",
    "        vae.optimizer.apply_gradients(zip(grads, vae.trainable_weights))\n",
    "\n",
    "        train_loss += total_loss\n",
    "\n",
    "    train_loss /= len(train_dataset)\n",
    "    train_loss_list.append(train_loss)\n",
    "    print(f\"Train Loss: {train_loss.numpy()}, KL Loss: {kl_loss.numpy()}, Reconstruction Loss: {reconstruction_loss.numpy()}\")\n",
    "\n",
    "    # Validation Loop\n",
    "    val_loss = 0\n",
    "    for val_step, (val_adjacency, val_features, val_scores) in enumerate(val_dataset):\n",
    "        # Forward pass\n",
    "        z_mean, z_log_var = vae.encoder([val_adjacency, val_features, val_scores])\n",
    "        z = vae.sampling([z_mean, z_log_var])\n",
    "        val_adj_reconstruction, val_feat_reconstruction = vae.decoder([z, val_scores])\n",
    "\n",
    "        # Compute losses\n",
    "        val_adj_loss = tf.reduce_mean(\n",
    "            tf.reduce_sum(keras.losses.binary_crossentropy(val_adjacency, val_adj_reconstruction), axis=(1, 2))\n",
    "        )\n",
    "        val_feat_loss = tf.reduce_mean(\n",
    "            tf.reduce_sum(keras.losses.categorical_crossentropy(val_features, val_feat_reconstruction), axis=1)\n",
    "        )\n",
    "        val_reconstruction_loss = 0.6*val_adj_loss + 0.4*val_feat_loss\n",
    "        val_kl_loss = -0.5 * tf.reduce_mean(\n",
    "            tf.reduce_sum(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=1)\n",
    "        )\n",
    "        val_total_loss = val_reconstruction_loss + beta * val_kl_loss\n",
    "\n",
    "        val_loss += val_total_loss\n",
    "\n",
    "    val_loss /= len(val_dataset)\n",
    "    val_loss_list.append(val_loss)\n",
    "    print(f\"Validation Loss: {val_loss.numpy()}, KL Loss: {val_kl_loss.numpy()}, Reconstruction Loss: {val_reconstruction_loss.numpy()}\")\n",
    "    print('BETA is: ', beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9f6319",
   "metadata": {
    "id": "RaEQJCNB2Gjh",
    "outputId": "90670ff4-20f8-4593-be08-c4507409ac90",
    "papermill": {
     "duration": 1.053027,
     "end_time": "2022-03-28T10:37:51.972530",
     "exception": false,
     "start_time": "2022-03-28T10:37:50.919503",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(EPOCHS), train_loss_list, label='Training Loss', marker='o')\n",
    "plt.plot(range(EPOCHS), val_loss_list, label='Validation Loss', marker='s')\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Training and Validation Loss Over Epochs', fontsize=16)\n",
    "plt.xlabel('Epochs', fontsize=14)\n",
    "plt.ylabel('Loss', fontsize=14)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadc626f",
   "metadata": {
    "id": "f9VTrM04-hcP",
    "papermill": {
     "duration": 0.906848,
     "end_time": "2022-03-28T10:37:53.741451",
     "exception": false,
     "start_time": "2022-03-28T10:37:52.834603",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Inferencing\n",
    "\n",
    "We would be inferring our model to predict over random latent space and try to generate 100 new valid molecules."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee36ff6",
   "metadata": {
    "id": "hicuVsE6-o8c",
    "papermill": {
     "duration": 0.858124,
     "end_time": "2022-03-28T10:37:55.452351",
     "exception": false,
     "start_time": "2022-03-28T10:37:54.594227",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Generate unique Molecules with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40d046f-967b-426d-b248-05d4b15fd784",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "# Create output directory if it doesn't exist\n",
    "output_dir = \"generated_molecules\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Get current timestamp for unique folder name\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "run_dir = os.path.join(output_dir, f\"run_{timestamp}\")\n",
    "os.makedirs(run_dir)\n",
    "\n",
    "valid_count = 0\n",
    "iterations = 100\n",
    "for i in range(iterations):\n",
    "    \n",
    "    # Random latent vector and target score\n",
    "    random_z = np.random.normal(size=(1, LATENT_DIM))\n",
    "    target_score = np.array([[0.5]]) \n",
    "\n",
    "    # Generate predictions\n",
    "    adjacency_pred, feature_pred = vae.decoder.predict([random_z, target_score])\n",
    "    adjacency_pred = adjacency_pred*3 #Denormalize adjacency matrix\n",
    "    # Post-process predictions\n",
    "    threshold = 0.5\n",
    "    adjacency_pred_processed = (adjacency_pred > threshold).astype(int)  # Binary\n",
    "    adjacency_pred_processed = np.maximum(\n",
    "        adjacency_pred_processed, \n",
    "        np.transpose(adjacency_pred_processed, (0, 1, 3, 2))  # Swap last two dimensions\n",
    "    )\n",
    "    feature_pred_processed = tf.one_hot(np.argmax(feature_pred, axis=-1), depth=ATOM_DIM).numpy()  # One-hot\n",
    "\n",
    "    # Debug prints\n",
    "    #print(\"Processed Adjacency Matrix Shape:\", adjacency_pred_processed[0].shape)\n",
    "    #print(\"Processed Feature Matrix Shape:\", feature_pred_processed[0].shape)\n",
    "\n",
    "    # Generate the molecule\n",
    "    generated_molecule = graph_to_molecule(adjacency_pred_processed[0], feature_pred_processed[0])\n",
    "\n",
    "    # Visualize or print the molecule\n",
    "    if generated_molecule:\n",
    "        valid_count += 1\n",
    "        smiles = Chem.MolToSmiles(generated_molecule)\n",
    "        \n",
    "        # Create filename using molecule index and SMILES string (truncated if too long)\n",
    "        truncated_smiles = smiles[:50]  # Truncate SMILES to prevent filename length issues\n",
    "        safe_smiles = \"\".join(c if c.isalnum() else \"_\" for c in truncated_smiles)  # Remove special characters\n",
    "        filename = f\"molecule_{valid_count:04d}_{safe_smiles}\"\n",
    "        \n",
    "        # Save the molecule image\n",
    "        img_path = os.path.join(run_dir, f\"{filename}.png\")\n",
    "        Draw.MolToFile(generated_molecule, img_path, size=(300, 300))\n",
    "        \n",
    "        # Save SMILES string to a text file\n",
    "        with open(os.path.join(run_dir, \"molecules.txt\"), \"a\") as f:\n",
    "            f.write(f\"Molecule {valid_count}: {smiles}\\n\")\n",
    "            \n",
    "    else:\n",
    "        print(\"Failed to generate a valid molecule.\")\n",
    "\n",
    "print(f\"\\nGeneration complete! Generated {valid_count} valid molecules out of {iterations} runs.\")\n",
    "#print(f\"Output directory: {run_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393de29c-4390-4ac1-b2e3-759b158e0fd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 451.695384,
   "end_time": "2022-03-28T10:38:34.884667",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-03-28T10:31:03.189283",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
